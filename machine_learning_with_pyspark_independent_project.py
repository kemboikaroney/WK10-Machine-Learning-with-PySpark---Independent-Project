# -*- coding: utf-8 -*-
"""Machine Learning with PySpark - Independent Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IFZZaoqb9Xn0tfrRUuZfFvXgJy1PTA0H
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier, LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit

# Create a SparkSession
spark = SparkSession.builder.appName("TelecomChurnPrediction").getOrCreate()

# Load the dataset
data = spark.read.csv("telecom_dataset.csv", header=True, inferSchema=True)

# Perform data preprocessing
data = data.dropna()

gender_indexer = StringIndexer(inputCol="Gender", outputCol="GenderIndex")
contract_indexer = StringIndexer(inputCol="Contract", outputCol="ContractIndex")
churn_indexer = StringIndexer(inputCol="Churn", outputCol="label")

indexers = [gender_indexer, contract_indexer, churn_indexer]
pipeline = Pipeline(stages=indexers)
data = pipeline.fit(data).transform(data)

assembler = VectorAssembler(
    inputCols=["GenderIndex", "Age", "ContractIndex", "MonthlyCharges", "TotalCharges"],
    outputCol="features"
)
data = assembler.transform(data)

# Split the data into training and testing sets
train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)

# Define the models to try
models = [
    RandomForestClassifier(labelCol="label", featuresCol="features", seed=42),
    LogisticRegression(labelCol="label", featuresCol="features")
]

# Create a list of parameter grids to search through
paramGrids = [
    ParamGridBuilder().addGrid(RandomForestClassifier.maxDepth, [5, 10]).build(),
    ParamGridBuilder().addGrid(LogisticRegression.regParam, [0.01, 0.1]).build()
]

# Create a list to store the accuracy for each model
accuracies = []

# Train and evaluate each model
for i in range(len(models)):
    model = models[i]
    paramGrid = paramGrids[i]
    
    evaluator = BinaryClassificationEvaluator(labelCol="label")
    tvs = TrainValidationSplit(estimator=model, estimatorParamMaps=paramGrid, evaluator=evaluator)
    
    # Train the model
    tvs_model = tvs.fit(train_data)
    
    # Make predictions
    predictions = tvs_model.transform(test_data)
    
    # Evaluate model performance
    accuracy = evaluator.evaluate(predictions)
    accuracies.append(accuracy)
    
    print("Model", i+1, "Accuracy:", accuracy)